{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7prmnb1UbJA"
      },
      "outputs": [],
      "source": [
        "!pip uninstall numpy scipy -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ub-Ps0OUeo8"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.26.4 scipy==1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp7mjODwUhuK"
      },
      "outputs": [],
      "source": [
        "!pip install logzero\n",
        "!pip install pyotp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqULkceYUiOd"
      },
      "outputs": [],
      "source": [
        "!pip install smartapi-python --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG73b0CHUkTc"
      },
      "outputs": [],
      "source": [
        "!pip install pandas-ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7dOej0VUmQS"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt4EyZSsUn69"
      },
      "outputs": [],
      "source": [
        "!pip install smartapi-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYEaNNmkUv3M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import logging\n",
        "from SmartApi import SmartConnect\n",
        "from pyotp import TOTP\n",
        "import urllib.request\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BCDuoUBUyT2"
      },
      "outputs": [],
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "logging.basicConfig(\n",
        "    level=logging.WARNING,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "DEFAULT_EXCHANGE = \"NSE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t2-HUyrVmXf"
      },
      "outputs": [],
      "source": [
        "class ImprovedExitDataset:\n",
        "    def __init__(self, df, verbose: bool = False):\n",
        "        self.df = df.copy()\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def process_data(self):\n",
        "        self.add_technical_indicators()\n",
        "        self.add_volatility_measures()\n",
        "        self.add_volume_analysis()\n",
        "        self.add_price_patterns()\n",
        "        self.add_support_resistance()\n",
        "        self.add_market_regime()\n",
        "        self.add_momentum_indicators()\n",
        "\n",
        "        critical_features = [\n",
        "            'rsi', 'macd', 'macd_hist', 'bb_width', 'atr_pct',\n",
        "            'volatility_10d', 'vol_ratio', 'volume_ratio',\n",
        "            'price_vs_ma20', 'price_vs_ma50',\n",
        "            'dist_to_resistance', 'dist_to_support',\n",
        "            'trend_strength', 'market_condition', 'momentum_score'\n",
        "        ]\n",
        "        self.df.dropna(subset=critical_features, inplace=True)\n",
        "        if self.verbose:\n",
        "            print(f\"processed rows: {len(self.df)}\")\n",
        "\n",
        "    def add_technical_indicators(self):\n",
        "        # RSI\n",
        "        delta = self.df['close'].diff()\n",
        "        gain = delta.clip(lower=0).rolling(14).mean()\n",
        "        loss = -delta.clip(upper=0).rolling(14).mean()\n",
        "        rs = gain / loss.replace(0, np.nan)\n",
        "        self.df['rsi'] = 100 - (100 / (1 + rs))\n",
        "        self.df['rsi_overbought'] = (self.df['rsi'] > 70).astype(int)\n",
        "        self.df['rsi_oversold'] = (self.df['rsi'] < 30).astype(int)\n",
        "\n",
        "        # MACD\n",
        "        ema_12 = self.df['close'].ewm(span=12, adjust=False).mean()\n",
        "        ema_26 = self.df['close'].ewm(span=26, adjust=False).mean()\n",
        "        self.df['macd'] = ema_12 - ema_26\n",
        "        self.df['macd_signal'] = self.df['macd'].ewm(span=9, adjust=False).mean()\n",
        "        self.df['macd_hist'] = self.df['macd'] - self.df['macd_signal']\n",
        "        self.df['macd_bullish_cross'] = ((self.df['macd'] > self.df['macd_signal']) &\n",
        "                                         (self.df['macd'].shift(1) <= self.df['macd_signal'].shift(1))).astype(int)\n",
        "        self.df['macd_bearish_cross'] = ((self.df['macd'] < self.df['macd_signal']) &\n",
        "                                         (self.df['macd'].shift(1) >= self.df['macd_signal'].shift(1))).astype(int)\n",
        "\n",
        "        # Bollinger Bands\n",
        "        bb_length, bb_std = 20, 2\n",
        "        basis = self.df['close'].rolling(bb_length).mean()\n",
        "        dev = bb_std * self.df['close'].rolling(bb_length).std()\n",
        "        self.df['bb_upper'] = basis + dev\n",
        "        self.df['bb_lower'] = basis - dev\n",
        "        self.df['bb_width'] = (self.df['bb_upper'] - self.df['bb_lower']) / basis\n",
        "        self.df['bb_position'] = (self.df['close'] - self.df['bb_lower']) / (self.df['bb_upper'] - self.df['bb_lower'])\n",
        "\n",
        "        # ATR\n",
        "        tr1 = self.df['high'] - self.df['low']\n",
        "        tr2 = (self.df['high'] - self.df['close'].shift()).abs()\n",
        "        tr3 = (self.df['low'] - self.df['close'].shift()).abs()\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        self.df['atr'] = tr.rolling(14).mean()\n",
        "        self.df['atr_pct'] = self.df['atr'] / self.df['close']\n",
        "\n",
        "    def add_volatility_measures(self):\n",
        "        self.df['returns'] = self.df['close'].pct_change()\n",
        "        self.df['volatility_5d'] = self.df['returns'].rolling(5).std()\n",
        "        self.df['volatility_10d'] = self.df['returns'].rolling(10).std()\n",
        "        self.df['volatility_21d'] = self.df['returns'].rolling(21).std()\n",
        "        self.df['vol_ratio'] = self.df['volatility_10d'] / self.df['volatility_21d'].replace(0, np.nan)\n",
        "        self.df['vol_expanding'] = (self.df['vol_ratio'] > 1.2).astype(int)\n",
        "        self.df['parkinson_vol'] = np.sqrt((1 / (4 * np.log(2))) *\n",
        "                                           ((np.log(self.df['high'] / self.df['low'])) ** 2).rolling(20).mean())\n",
        "\n",
        "    def add_volume_analysis(self):\n",
        "        self.df['volume_ma20'] = self.df['volume'].rolling(20).mean()\n",
        "        self.df['volume_ratio'] = self.df['volume'] / self.df['volume_ma20'].replace(0, np.nan)\n",
        "        self.df['volume_spike'] = (self.df['volume_ratio'] > 2).astype(int)\n",
        "        self.df['obv'] = (np.sign(self.df['returns']) * self.df['volume']).cumsum()\n",
        "        self.df['obv_ma20'] = self.df['obv'].rolling(20).mean()\n",
        "        self.df['obv_trend'] = np.where(self.df['obv'] > self.df['obv_ma20'], 1, -1)\n",
        "        self.df['vpt'] = (self.df['returns'] * self.df['volume']).cumsum()\n",
        "        self.df['vpt_ma20'] = self.df['vpt'].rolling(20).mean()\n",
        "\n",
        "    def add_price_patterns(self):\n",
        "        self.df['ma_20'] = self.df['close'].rolling(20).mean()\n",
        "        self.df['ma_50'] = self.df['close'].rolling(50).mean()\n",
        "        self.df['ma_200'] = self.df['close'].rolling(200).mean()\n",
        "        self.df['price_vs_ma20'] = self.df['close'] / self.df['ma_20'] - 1\n",
        "        self.df['price_vs_ma50'] = self.df['close'] / self.df['ma_50'] - 1\n",
        "        self.df['price_vs_ma200'] = (self.df['close'] / self.df['ma_200'] - 1)\n",
        "        self.df['price_vs_ma200'] = self.df['price_vs_ma200'].fillna(0)\n",
        "        self.df['ma_golden_cross'] = ((self.df['ma_50'] > self.df['ma_200']) &\n",
        "                                      (self.df['ma_50'].shift(1) <= self.df['ma_200'].shift(1))).astype(int)\n",
        "        self.df['ma_death_cross'] = ((self.df['ma_50'] < self.df['ma_200']) &\n",
        "                                     (self.df['ma_50'].shift(1) >= self.df['ma_200'].shift(1))).astype(int)\n",
        "        self.df['daily_range'] = (self.df['high'] - self.df['low']) / self.df['close']\n",
        "        self.df['range_vs_atr'] = self.df['daily_range'] / self.df['atr_pct'].replace(0, np.nan)\n",
        "\n",
        "    def add_support_resistance(self):\n",
        "        self.df['recent_high_10'] = self.df['high'].rolling(10).max()\n",
        "        self.df['recent_low_10'] = self.df['low'].rolling(10).min()\n",
        "        self.df['recent_high_20'] = self.df['high'].rolling(20).max()\n",
        "        self.df['recent_low_20'] = self.df['low'].rolling(20).min()\n",
        "        self.df['dist_to_resistance'] = (self.df['recent_high_20'] - self.df['close']) / self.df['close']\n",
        "        self.df['dist_to_support'] = (self.df['close'] - self.df['recent_low_20']) / self.df['close']\n",
        "        self.df['near_resistance'] = (self.df['dist_to_resistance'] < 0.02).astype(int)\n",
        "        self.df['near_support'] = (self.df['dist_to_support'] < 0.02).astype(int)\n",
        "\n",
        "    def add_market_regime(self):\n",
        "        self.df['trend_strength'] = abs(self.df['close'].pct_change(20).rolling(5).mean())\n",
        "        self.df['market_condition'] = 0\n",
        "        self.df.loc[self.df['close'] > self.df['ma_200'] * 1.05, 'market_condition'] = 1\n",
        "        self.df.loc[self.df['close'] < self.df['ma_200'] * 0.95, 'market_condition'] = -1\n",
        "        try:\n",
        "            high_low = self.df['high'] - self.df['low']\n",
        "            high_close = (self.df['high'] - self.df['close'].shift()).abs()\n",
        "            low_close = (self.df['low'] - self.df['close'].shift()).abs()\n",
        "            tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "            atr_14 = tr.rolling(14).mean()\n",
        "            up_move = self.df['high'] - self.df['high'].shift()\n",
        "            down_move = self.df['low'].shift() - self.df['low']\n",
        "            pos_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0), index=self.df.index)\n",
        "            neg_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0), index=self.df.index)\n",
        "            pos_dm_14 = pos_dm.rolling(14).mean()\n",
        "            neg_dm_14 = neg_dm.rolling(14).mean()\n",
        "            pos_di = 100 * pos_dm_14 / atr_14\n",
        "            neg_di = 100 * neg_dm_14 / atr_14\n",
        "            dx = 100 * (pos_di - neg_di).abs() / (pos_di + neg_di)\n",
        "            self.df['adx'] = dx.rolling(14).mean()\n",
        "            self.df['adx'] = self.df['adx'].fillna(0)\n",
        "        except Exception:\n",
        "            self.df['adx'] = 25.0\n",
        "\n",
        "    def add_momentum_indicators(self):\n",
        "        self.df['roc_10'] = self.df['close'].pct_change(10)\n",
        "        self.df['roc_20'] = self.df['close'].pct_change(20)\n",
        "        self.df['momentum_score'] = (\n",
        "            (self.df['rsi'] - 50) / 50 * 0.3 +\n",
        "            np.sign(self.df['macd_hist']) * 0.2 +\n",
        "            (self.df['price_vs_ma20']) * 0.3 +\n",
        "            (self.df['obv_trend']) * 0.2\n",
        "        )\n",
        "        low_14 = self.df['low'].rolling(14).min()\n",
        "        high_14 = self.df['high'].rolling(14).max()\n",
        "        self.df['stoch_k'] = 100 * (self.df['close'] - low_14) / (high_14 - low_14)\n",
        "        self.df['stoch_d'] = self.df['stoch_k'].rolling(3).mean()\n",
        "\n",
        "    def create_realistic_exit_dataset(self, position_type='long', max_holding_days=20):\n",
        "        df = self.df.copy()\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "\n",
        "        exit_points = []\n",
        "        if position_type == 'long':\n",
        "            profit_target, stop_loss, trailing_stop_pct = 0.08, 0.04, 0.03\n",
        "        else:\n",
        "            profit_target, stop_loss, trailing_stop_pct = 0.08, 0.04, 0.03\n",
        "\n",
        "        for i in range(len(df) - max_holding_days - 1):\n",
        "            entry_idx = i\n",
        "            entry_data = df.iloc[entry_idx].copy()\n",
        "            entry_price = entry_data['close']\n",
        "\n",
        "            future_window = df.iloc[i + 1:i + max_holding_days + 1]\n",
        "            if future_window.empty:\n",
        "                continue\n",
        "\n",
        "            exit_idx = None\n",
        "            exit_reason = None\n",
        "            peak_price, trough_price = entry_price, entry_price\n",
        "\n",
        "            for j, (date, row) in enumerate(future_window.iterrows()):\n",
        "                current_price = row['close']\n",
        "                holding_days = j + 1\n",
        "\n",
        "                if position_type == 'long':\n",
        "                    peak_price = max(peak_price, current_price)\n",
        "                    returns = (current_price - entry_price) / entry_price\n",
        "                    drawdown_from_peak = (peak_price - current_price) / peak_price if peak_price > current_price else 0\n",
        "                    if returns >= profit_target:\n",
        "                        exit_idx, exit_reason = date, 'profit_target'; break\n",
        "                    elif returns <= -stop_loss:\n",
        "                        exit_idx, exit_reason = date, 'stop_loss'; break\n",
        "                    elif drawdown_from_peak >= trailing_stop_pct and returns > 0.01:\n",
        "                        exit_idx, exit_reason = date, 'trailing_stop'; break\n",
        "                    elif holding_days >= 5 and entry_data['momentum_score'] > 0.2 and row['momentum_score'] < -0.2:\n",
        "                        exit_idx, exit_reason = date, 'momentum_reversal'; break\n",
        "                    elif holding_days >= 3 and row['rsi'] > 75 and j > 0 and future_window.iloc[j-1]['rsi'] > row['rsi']:\n",
        "                        exit_idx, exit_reason = date, 'rsi_reversal'; break\n",
        "                else:\n",
        "                    trough_price = min(trough_price, current_price)\n",
        "                    returns = (entry_price - current_price) / entry_price\n",
        "                    drawup_from_trough = (current_price - trough_price) / trough_price if current_price > trough_price else 0\n",
        "                    if returns >= profit_target:\n",
        "                        exit_idx, exit_reason = date, 'profit_target'; break\n",
        "                    elif returns <= -stop_loss:\n",
        "                        exit_idx, exit_reason = date, 'stop_loss'; break\n",
        "                    elif drawup_from_trough >= trailing_stop_pct and returns > 0.01:\n",
        "                        exit_idx, exit_reason = date, 'trailing_stop'; break\n",
        "                    elif holding_days >= 5 and entry_data['momentum_score'] < -0.2 and row['momentum_score'] > 0.2:\n",
        "                        exit_idx, exit_reason = date, 'momentum_reversal'; break\n",
        "                    elif holding_days >= 3 and row['rsi'] < 25 and j > 0 and future_window.iloc[j-1]['rsi'] < row['rsi']:\n",
        "                        exit_idx, exit_reason = date, 'rsi_reversal'; break\n",
        "\n",
        "            if exit_idx is None:\n",
        "                exit_idx, exit_reason, holding_days = future_window.index[-1], 'time_exit', max_holding_days\n",
        "\n",
        "            exit_data = df.loc[exit_idx].copy()\n",
        "            entry_date = df.index[entry_idx]\n",
        "\n",
        "            if position_type == 'long':\n",
        "                returns = (exit_data['close'] - entry_price) / entry_price\n",
        "                max_gain = (max(peak_price, exit_data['close']) - entry_price) / entry_price\n",
        "                try:\n",
        "                    min_price_during_hold = df.iloc[i + 1:df.index.get_loc(exit_idx) + 1]['close'].min()\n",
        "                    max_drawdown = (peak_price - min_price_during_hold) / peak_price if peak_price > 0 else 0\n",
        "                except Exception:\n",
        "                    max_drawdown = 0\n",
        "            else:\n",
        "                returns = (entry_price - exit_data['close']) / entry_price\n",
        "                max_gain = (entry_price - min(trough_price, exit_data['close'])) / entry_price\n",
        "                try:\n",
        "                    max_price_during_hold = df.iloc[i + 1:df.index.get_loc(exit_idx) + 1]['close'].max()\n",
        "                    max_drawdown = (max_price_during_hold - trough_price) / trough_price if trough_price > 0 else 0\n",
        "                except Exception:\n",
        "                    max_drawdown = 0\n",
        "\n",
        "            feature_columns = [\n",
        "                'rsi', 'rsi_overbought', 'rsi_oversold', 'macd', 'macd_hist', 'macd_bullish_cross', 'macd_bearish_cross',\n",
        "                'bb_width', 'bb_position', 'atr_pct', 'volatility_10d', 'volatility_21d', 'vol_ratio', 'vol_expanding',\n",
        "                'volume_ratio', 'volume_spike', 'obv_trend', 'price_vs_ma20', 'price_vs_ma50', 'price_vs_ma200',\n",
        "                'ma_golden_cross', 'ma_death_cross', 'daily_range', 'range_vs_atr', 'dist_to_resistance', 'dist_to_support',\n",
        "                'near_resistance', 'near_support', 'trend_strength', 'market_condition', 'adx', 'momentum_score', 'roc_10',\n",
        "                'roc_20', 'stoch_k', 'stoch_d'\n",
        "            ]\n",
        "\n",
        "            feature_row = {col: entry_data[col] for col in feature_columns if col in entry_data.index}\n",
        "            feature_row.update({\n",
        "                'holding_days': int(holding_days),\n",
        "                'returns': returns,\n",
        "                'max_gain': max_gain,\n",
        "                'max_drawdown': max_drawdown,\n",
        "                'exit_reason': exit_reason,\n",
        "                'position_type': position_type,\n",
        "                'entry_date': entry_date,\n",
        "                'exit_date': pd.to_datetime(exit_idx),\n",
        "                'success': 1 if returns > 0 else 0\n",
        "            })\n",
        "            exit_points.append(feature_row)\n",
        "\n",
        "        exit_df = pd.DataFrame(exit_points)\n",
        "        if exit_df.empty and self.verbose:\n",
        "            print(\"no exit points created\")\n",
        "        exit_df = exit_df.dropna()\n",
        "        if self.verbose:\n",
        "            print(f\"final dataset samples: {len(exit_df)}\")\n",
        "        return exit_df\n",
        "\n",
        "    def get_position_features(self, position_type):\n",
        "        features = [\n",
        "            'rsi', 'rsi_overbought', 'rsi_oversold', 'macd', 'macd_hist', 'macd_bullish_cross', 'macd_bearish_cross',\n",
        "            'bb_width', 'bb_position', 'atr_pct', 'volatility_10d', 'volatility_21d', 'vol_ratio', 'vol_expanding',\n",
        "            'volume_ratio', 'volume_spike', 'obv_trend', 'price_vs_ma20', 'price_vs_ma50', 'price_vs_ma200',\n",
        "            'ma_golden_cross', 'ma_death_cross', 'daily_range', 'range_vs_atr', 'dist_to_resistance', 'dist_to_support',\n",
        "            'near_resistance', 'near_support', 'trend_strength', 'market_condition', 'adx', 'momentum_score', 'roc_10',\n",
        "            'roc_20', 'stoch_k', 'stoch_d'\n",
        "        ]\n",
        "        missing = [c for c in features if c not in self.df.columns]\n",
        "        if missing:\n",
        "            raise KeyError(f\"Missing features: {missing}\")\n",
        "        return self.df[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y52_RidHVqu2"
      },
      "outputs": [],
      "source": [
        "class ImprovedExitPredictor:\n",
        "    def __init__(self, exit_df, position_type, verbose: bool = False):\n",
        "        self.exit_df = exit_df.copy()\n",
        "        self.position_type = position_type\n",
        "        self.model = None\n",
        "        self.features = None\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def prepare_features(self):\n",
        "        feature_columns = [\n",
        "            'rsi', 'rsi_overbought', 'rsi_oversold', 'macd', 'macd_hist', 'macd_bullish_cross', 'macd_bearish_cross',\n",
        "            'bb_width', 'bb_position', 'atr_pct', 'volatility_10d', 'volatility_21d', 'vol_ratio', 'vol_expanding',\n",
        "            'volume_ratio', 'volume_spike', 'obv_trend', 'price_vs_ma20', 'price_vs_ma50', 'price_vs_ma200',\n",
        "            'ma_golden_cross', 'ma_death_cross', 'daily_range', 'range_vs_atr', 'dist_to_resistance', 'dist_to_support',\n",
        "            'near_resistance', 'near_support', 'trend_strength', 'market_condition', 'adx', 'momentum_score', 'roc_10',\n",
        "            'roc_20', 'stoch_k', 'stoch_d'\n",
        "        ]\n",
        "        self.features = self.exit_df[feature_columns]\n",
        "        self.holding_days_target = self.exit_df['holding_days']\n",
        "        self.success_target = self.exit_df['success']\n",
        "        self.returns_target = self.exit_df['returns']\n",
        "\n",
        "    def train(self, n_trials=30):\n",
        "        self.prepare_features()\n",
        "        train_size = int(len(self.features) * 0.8)\n",
        "        X_train = self.features.iloc[:train_size]\n",
        "        X_test = self.features.iloc[train_size:]\n",
        "        y_hold_train = self.holding_days_target.iloc[:train_size]\n",
        "        y_hold_test = self.holding_days_target.iloc[train_size:]\n",
        "        y_success_train = self.success_target.iloc[:train_size]\n",
        "        y_success_test = self.success_target.iloc[train_size:]\n",
        "        y_returns_train = self.returns_target.iloc[:train_size]\n",
        "        y_returns_test = self.returns_target.iloc[train_size:]\n",
        "        if self.verbose:\n",
        "            print(f\"Training {self.position_type} models... n={len(X_train)} success={y_success_train.mean():.1%}\")\n",
        "        hold_model = self.train_hold_model(X_train, y_hold_train, n_trials)\n",
        "        success_model = self.train_success_model(X_train, y_success_train, n_trials)\n",
        "        returns_model = self.train_returns_model(X_train, y_returns_train, n_trials)\n",
        "        hold_rmse = np.sqrt(mean_squared_error(y_hold_test, hold_model.predict(X_test)))\n",
        "        success_pred = (success_model.predict(X_test) > 0.5).astype(int)\n",
        "        success_acc = accuracy_score(y_success_test, success_pred)\n",
        "        success_f1 = f1_score(y_success_test, success_pred)\n",
        "        returns_rmse = np.sqrt(mean_squared_error(y_returns_test, returns_model.predict(X_test)))\n",
        "        self.model = {\n",
        "            'hold_model': hold_model,\n",
        "            'success_model': success_model,\n",
        "            'returns_model': returns_model,\n",
        "            'metrics': {\n",
        "                'hold_rmse': hold_rmse,\n",
        "                'success_accuracy': success_acc,\n",
        "                'success_f1': success_f1,\n",
        "                'returns_rmse': returns_rmse\n",
        "            }\n",
        "        }\n",
        "        return self.model\n",
        "\n",
        "    def train_hold_model(self, X, y, n_trials):\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'objective': 'regression', 'metric': 'rmse', 'verbosity': -1,\n",
        "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
        "                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
        "                'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
        "            }\n",
        "            tscv = TimeSeriesSplit(n_splits=5)\n",
        "            scores = []\n",
        "            for tr, va in tscv.split(X):\n",
        "                dtrain = lgb.Dataset(X.iloc[tr], label=y.iloc[tr])\n",
        "                dval = lgb.Dataset(X.iloc[va], label=y.iloc[va], reference=dtrain)\n",
        "                model = lgb.train(params, dtrain, valid_sets=[dval], num_boost_round=200,\n",
        "                                  callbacks=[lgb.early_stopping(30, verbose=False)])\n",
        "                scores.append(np.sqrt(mean_squared_error(y.iloc[va], model.predict(X.iloc[va]))))\n",
        "            return np.mean(scores)\n",
        "        study = optuna.create_study(direction='minimize'); study.optimize(objective, n_trials=n_trials)\n",
        "        best_params = study.best_params; best_params.update({'objective': 'regression', 'metric': 'rmse', 'verbosity': -1})\n",
        "        return lgb.train(best_params, lgb.Dataset(X, label=y), num_boost_round=200)\n",
        "\n",
        "    def train_success_model(self, X, y, n_trials):\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1,\n",
        "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
        "                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
        "                'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
        "            }\n",
        "            tscv = TimeSeriesSplit(n_splits=5)\n",
        "            scores = []\n",
        "            for tr, va in tscv.split(X):\n",
        "                dtrain = lgb.Dataset(X.iloc[tr], label=y.iloc[tr])\n",
        "                dval = lgb.Dataset(X.iloc[va], label=y.iloc[va], reference=dtrain)\n",
        "                model = lgb.train(params, dtrain, valid_sets=[dval], num_boost_round=200,\n",
        "                                  callbacks=[lgb.early_stopping(30, verbose=False)])\n",
        "                scores.append(f1_score(y.iloc[va], (model.predict(X.iloc[va]) > 0.5).astype(int)))\n",
        "            return np.mean(scores)\n",
        "        study = optuna.create_study(direction='maximize'); study.optimize(objective, n_trials=n_trials)\n",
        "        best_params = study.best_params; best_params.update({'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1})\n",
        "        return lgb.train(best_params, lgb.Dataset(X, label=y), num_boost_round=200)\n",
        "\n",
        "    def train_returns_model(self, X, y, n_trials):\n",
        "        return self.train_hold_model(X, y, n_trials)\n",
        "\n",
        "    def predict(self, features, confidence_threshold=0.6):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained\")\n",
        "        hold_days = max(1, round(self.model['hold_model'].predict(features)[0]))\n",
        "        success_prob = self.model['success_model'].predict(features)[0]\n",
        "        predicted_returns = self.model['returns_model'].predict(features)[0]\n",
        "        risk_score = self._calculate_risk_score(features.iloc[0], success_prob, predicted_returns)\n",
        "        confidence = self._calculate_confidence(success_prob, predicted_returns, risk_score)\n",
        "        if success_prob < 0.4:\n",
        "            recommendation = \"AVOID\"\n",
        "        elif success_prob < confidence_threshold:\n",
        "            recommendation = \"RISKY\"\n",
        "        elif confidence > 0.7:\n",
        "            recommendation = \"STRONG\"\n",
        "        else:\n",
        "            recommendation = \"MODERATE\"\n",
        "        return {\n",
        "            'holding_days': hold_days,\n",
        "            'success_probability': success_prob,\n",
        "            'predicted_returns': predicted_returns,\n",
        "            'risk_score': risk_score,\n",
        "            'confidence': confidence,\n",
        "            'recommendation': recommendation,\n",
        "            'position_type': self.position_type,\n",
        "            'ticker': None\n",
        "        }\n",
        "\n",
        "    def _calculate_risk_score(self, features, success_prob, predicted_returns):\n",
        "        risk_factors = []\n",
        "        risk_factors.append(min(features['volatility_10d'] * 10, 1.0) * 0.25)\n",
        "        risk_factors.append((0.5 if (features['rsi'] > 75 or features['rsi'] < 25) else 0) * 0.15)\n",
        "        risk_factors.append((1 - success_prob) * 0.30)\n",
        "        risk_factors.append((0.7 if abs(predicted_returns) > 0.10 else 0) * 0.15)\n",
        "        risk_factors.append((0.6 if features['market_condition'] == 0 else 0.3) * 0.15)\n",
        "        return float(np.clip(sum(risk_factors), 0, 1))\n",
        "\n",
        "    def _calculate_confidence(self, success_prob, predicted_returns, risk_score):\n",
        "        base_confidence = success_prob\n",
        "        risk_adjusted = base_confidence * (1 - risk_score * 0.5)\n",
        "        if abs(predicted_returns) > 0.15:\n",
        "            magnitude_penalty = 0.3\n",
        "        elif abs(predicted_returns) > 0.08:\n",
        "            magnitude_penalty = 0.15\n",
        "        else:\n",
        "            magnitude_penalty = 0\n",
        "        final_confidence = risk_adjusted * (1 - magnitude_penalty)\n",
        "        return float(np.clip(final_confidence, 0, 1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiqOXMG4V03c"
      },
      "outputs": [],
      "source": [
        "class ExitStrategySystem:\n",
        "    def __init__(self, api_key, user_id, password, totp_key, verbose: bool = False):\n",
        "        self.api_key = api_key\n",
        "        self.user_id = user_id\n",
        "        self.password = password\n",
        "        self.totp_key = totp_key\n",
        "        self.client = SmartConnect(api_key=self.api_key)\n",
        "        self.session_data = None\n",
        "        self.instrument_list = None\n",
        "        self.trained_models = {}\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def login(self):\n",
        "        totp = TOTP(self.totp_key).now()\n",
        "        self.session_data = self.client.generateSession(self.user_id, self.password, totp)\n",
        "        if self.verbose:\n",
        "            print(\"login ok\")\n",
        "\n",
        "    def fetch_instruments(self, url=\"https://margincalculator.angelbroking.com/OpenAPI_File/files/OpenAPIScripMaster.json\"):\n",
        "        response = urllib.request.urlopen(url)\n",
        "        self.instrument_list = json.loads(response.read())\n",
        "        if self.verbose:\n",
        "            print(f\"instruments: {len(self.instrument_list)}\")\n",
        "\n",
        "    def token_lookup(self, ticker, exchange=DEFAULT_EXCHANGE):\n",
        "        for instrument in self.instrument_list:\n",
        "            if instrument[\"name\"] == ticker and instrument[\"exch_seg\"] == exchange and instrument[\"symbol\"].split('-')[-1] == \"EQ\":\n",
        "                return instrument[\"token\"]\n",
        "        return None\n",
        "\n",
        "    def symbol_lookup(self, token, exchange=DEFAULT_EXCHANGE):\n",
        "        for instrument in self.instrument_list:\n",
        "            if instrument[\"token\"] == token and instrument[\"exch_seg\"] == exchange and instrument[\"symbol\"].split('-')[-1] == \"EQ\":\n",
        "                return instrument[\"name\"]\n",
        "        return None\n",
        "\n",
        "    def get_candle_data(self, symbol, from_date, to_date, interval=\"ONE_DAY\", exchange=DEFAULT_EXCHANGE):\n",
        "        token = self.token_lookup(symbol, exchange)\n",
        "        if not token:\n",
        "            if self.verbose:\n",
        "                print(f\"token not found for {symbol}\")\n",
        "            return None\n",
        "        params = {\n",
        "            \"exchange\": exchange,\n",
        "            \"symboltoken\": str(token),\n",
        "            \"interval\": interval,\n",
        "            \"fromdate\": from_date,\n",
        "            \"todate\": to_date\n",
        "        }\n",
        "        data = self.client.getCandleData(params)\n",
        "        if \"data\" in data and data[\"data\"]:\n",
        "            df = pd.DataFrame(data[\"data\"], columns=[\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
        "            df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
        "            df['date'] = df['datetime'].dt.date\n",
        "            df.drop(columns='datetime', inplace=True)\n",
        "            df.set_index('date', inplace=True)\n",
        "            return df\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(f\"no data for {symbol}\")\n",
        "            return None\n",
        "\n",
        "    def predict_exit_signals(self, ticker, current_date, horizon_days=5, n_trials=20, lookback_years=5):\n",
        "        try:\n",
        "            if ticker not in self.trained_models:\n",
        "                long_model, short_model = self.train_exit_models(\n",
        "                    ticker, current_date - timedelta(days=1), lookback_years=lookback_years, n_trials=n_trials\n",
        "                )\n",
        "                if long_model is None or short_model is None:\n",
        "                    return None, None\n",
        "                self.trained_models[ticker] = {'long': long_model, 'short': short_model}\n",
        "            long_model = self.trained_models[ticker]['long']\n",
        "            short_model = self.trained_models[ticker]['short']\n",
        "            long_features, short_features = self.get_prediction_features(ticker, current_date)\n",
        "            if long_features is None or short_features is None:\n",
        "                return None, None\n",
        "            long_exit_signal = long_model.predict(long_features)\n",
        "            short_exit_signal = short_model.predict(short_features)\n",
        "            long_exit_signal['ticker'] = ticker\n",
        "            short_exit_signal['ticker'] = ticker\n",
        "            return long_exit_signal, short_exit_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"prediction error {ticker}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def train_exit_models(self, ticker, prediction_date, lookback_years=5, n_trials=20):\n",
        "        long_exit_df, short_exit_df = self.prepare_exit_datasets(ticker, prediction_date, lookback_years)\n",
        "        if long_exit_df is None or short_exit_df is None or long_exit_df.empty or short_exit_df.empty:\n",
        "            return None, None\n",
        "        long_exit_model = ImprovedExitPredictor(long_exit_df, position_type='long', verbose=False)\n",
        "        long_exit_model.train(n_trials=n_trials)\n",
        "        short_exit_model = ImprovedExitPredictor(short_exit_df, position_type='short', verbose=False)\n",
        "        short_exit_model.train(n_trials=n_trials)\n",
        "        return long_exit_model, short_exit_model\n",
        "\n",
        "    def prepare_exit_datasets(self, ticker, end_date, lookback_years=5):\n",
        "        start_date = (end_date - relativedelta(years=lookback_years)).strftime(\"%Y-%m-%d %H:%M\")\n",
        "        end_date_str = end_date.strftime(\"%Y-%m-%d %H:%M\")\n",
        "        df = self.get_candle_data(ticker, start_date, end_date_str)\n",
        "        if df is None or df.empty:\n",
        "            return None, None\n",
        "        exit_analyzer = ImprovedExitDataset(df, verbose=False)\n",
        "        exit_analyzer.process_data()\n",
        "        if exit_analyzer.df.empty:\n",
        "            return None, None\n",
        "        long_exit_df = exit_analyzer.create_realistic_exit_dataset(position_type='long')\n",
        "        short_exit_df = exit_analyzer.create_realistic_exit_dataset(position_type='short')\n",
        "        if long_exit_df.empty or short_exit_df.empty:\n",
        "            return None, None\n",
        "        return long_exit_df, short_exit_df\n",
        "\n",
        "    def get_prediction_features(self, ticker, current_date):\n",
        "        start_date = (current_date - timedelta(days=400)).strftime(\"%Y-%m-%d %H:%M\")\n",
        "        end_date = current_date.strftime(\"%Y-%m-%d %H:%M\")\n",
        "        df = self.get_candle_data(ticker, start_date, end_date)\n",
        "        if df is None or df.empty:\n",
        "            return None, None\n",
        "        exit_analyzer = ImprovedExitDataset(df, verbose=False)\n",
        "        exit_analyzer.process_data()\n",
        "        if exit_analyzer.df.empty:\n",
        "            return None, None\n",
        "        long_features = exit_analyzer.get_position_features('long')\n",
        "        short_features = exit_analyzer.get_position_features('short')\n",
        "        if long_features.empty or short_features.empty:\n",
        "            return None, None\n",
        "        return long_features.iloc[[-1]], short_features.iloc[[-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53Yu1YsAHvSr"
      },
      "outputs": [],
      "source": [
        "class StopLossCalculator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        exit_system,\n",
        "        atr_period: int = 14,\n",
        "        lookback_days: int = 60,\n",
        "        atr_mult_strong: float = 1.8,\n",
        "        atr_mult_moderate: float = 1.2,\n",
        "        min_sl_pct: float = 0.01,\n",
        "        max_sl_pct: float = 0.06,\n",
        "        tick_size: float = 0.05\n",
        "    ):\n",
        "        self.exit_system = exit_system\n",
        "        self.atr_period = atr_period\n",
        "        self.lookback_days = lookback_days\n",
        "        self.atr_mult_strong = atr_mult_strong\n",
        "        self.atr_mult_moderate = atr_mult_moderate\n",
        "        self.min_sl_pct = min_sl_pct\n",
        "        self.max_sl_pct = max_sl_pct\n",
        "        self.tick_size = tick_size\n",
        "\n",
        "    def _compute_atr(self, df: pd.DataFrame) -> float:\n",
        "        high_low = df['high'] - df['low']\n",
        "        high_close = (df['high'] - df['close'].shift()).abs()\n",
        "        low_close = (df['low'] - df['close'].shift()).abs()\n",
        "        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(self.atr_period).mean()\n",
        "        return float(atr.iloc[-1])\n",
        "\n",
        "    def _round_price(self, price: float) -> float:\n",
        "        if self.tick_size <= 0:\n",
        "            return float(price)\n",
        "        return float(round(price / self.tick_size) * self.tick_size)\n",
        "\n",
        "    def _get_price_and_atr(self, ticker: str, prediction_date: datetime):\n",
        "        from_date = (prediction_date - timedelta(days=self.lookback_days)).strftime(\"%Y-%m-%d %H:%M\")\n",
        "        to_date = prediction_date.strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "        df = self.exit_system.get_candle_data(\n",
        "            symbol=ticker,\n",
        "            from_date=from_date,\n",
        "            to_date=to_date,\n",
        "            interval=\"ONE_DAY\"\n",
        "        )\n",
        "        if df is None or df.empty:\n",
        "            return None, None\n",
        "\n",
        "        df = df.sort_index()\n",
        "        if len(df) < self.atr_period + 2:\n",
        "            return None, None\n",
        "\n",
        "        last_close = float(df['close'].iloc[-1])\n",
        "        atr_value = self._compute_atr(df)\n",
        "        if not np.isfinite(atr_value) or atr_value <= 0:\n",
        "            return None, None\n",
        "\n",
        "        return last_close, atr_value\n",
        "\n",
        "    def _compute_sl_for_side(self, side: str, rec_label: str, price: float, atr_value: float):\n",
        "        if rec_label == 'STRONG':\n",
        "            atr_mult = self.atr_mult_strong\n",
        "        else:\n",
        "            atr_mult = self.atr_mult_moderate\n",
        "\n",
        "        sl_distance = atr_mult * atr_value\n",
        "\n",
        "        if side == 'long':\n",
        "            sl_price = price - sl_distance\n",
        "            sl_pct = sl_distance / price\n",
        "        else:\n",
        "            sl_price = price + sl_distance\n",
        "            sl_pct = sl_distance / price\n",
        "\n",
        "        sl_pct = float(np.clip(sl_pct, self.min_sl_pct, self.max_sl_pct))\n",
        "\n",
        "        if side == 'long':\n",
        "            sl_price = price * (1 - sl_pct)\n",
        "        else:\n",
        "            sl_price = price * (1 + sl_pct)\n",
        "\n",
        "        sl_price = self._round_price(sl_price)\n",
        "        return sl_pct, sl_price\n",
        "\n",
        "    def add_stop_losses(self, predictions_df: pd.DataFrame, prediction_date: datetime) -> pd.DataFrame:\n",
        "        df = predictions_df.copy()\n",
        "        df['long_sl_pct'] = np.nan\n",
        "        df['long_sl_price'] = np.nan\n",
        "        df['short_sl_pct'] = np.nan\n",
        "        df['short_sl_price'] = np.nan\n",
        "\n",
        "        atr_cache = {}\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            ticker = row['ticker']\n",
        "\n",
        "            if ticker not in atr_cache:\n",
        "                try:\n",
        "                    last_close, atr_value = self._get_price_and_atr(ticker, prediction_date)\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"SL calc: failed to get ATR for {ticker}: {e}\")\n",
        "                    atr_cache[ticker] = (None, None)\n",
        "                    continue\n",
        "                atr_cache[ticker] = (last_close, atr_value)\n",
        "            else:\n",
        "                last_close, atr_value = atr_cache[ticker]\n",
        "\n",
        "            if last_close is None or atr_value is None:\n",
        "                continue\n",
        "\n",
        "            long_rec = row['long_recommendation']\n",
        "            if long_rec in ('STRONG', 'MODERATE'):\n",
        "                sl_pct, sl_price = self._compute_sl_for_side(\n",
        "                    side='long',\n",
        "                    rec_label=long_rec,\n",
        "                    price=last_close,\n",
        "                    atr_value=atr_value\n",
        "                )\n",
        "                df.at[idx, 'long_sl_pct'] = sl_pct\n",
        "                df.at[idx, 'long_sl_price'] = sl_price\n",
        "\n",
        "            short_rec = row['short_recommendation']\n",
        "            if short_rec in ('STRONG', 'MODERATE'):\n",
        "                sl_pct, sl_price = self._compute_sl_for_side(\n",
        "                    side='short',\n",
        "                    rec_label=short_rec,\n",
        "                    price=last_close,\n",
        "                    atr_value=atr_value\n",
        "                )\n",
        "                df.at[idx, 'short_sl_pct'] = sl_pct\n",
        "                df.at[idx, 'short_sl_price'] = sl_price\n",
        "\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k89yQFJzIEB2"
      },
      "outputs": [],
      "source": [
        "class SimpleSLBacktester:\n",
        "    def __init__(\n",
        "        self,\n",
        "        exit_system,\n",
        "        max_holding_days=20,\n",
        "        atr_period=14,\n",
        "        atr_mult=1.5\n",
        "    ):\n",
        "        self.exit_system = exit_system\n",
        "        self.max_holding_days = max_holding_days\n",
        "        self.atr_period = atr_period\n",
        "        self.atr_mult = atr_mult\n",
        "\n",
        "    def _compute_atr_series(self, df: pd.DataFrame) -> pd.Series:\n",
        "        high_low = df['high'] - df['low']\n",
        "        high_close = (df['high'] - df['close'].shift()).abs()\n",
        "        low_close = (df['low'] - df['close'].shift()).abs()\n",
        "        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(self.atr_period).mean()\n",
        "        return atr\n",
        "\n",
        "    def backtest_single_ticker(self, ticker: str, start_date: datetime, end_date: datetime, position_type: str = 'long'):\n",
        "        from_str = start_date.strftime(\"%Y-%m-%d %H:%M\")\n",
        "        to_str = end_date.strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "        df = self.exit_system.get_candle_data(\n",
        "            symbol=ticker,\n",
        "            from_date=from_str,\n",
        "            to_date=to_str,\n",
        "            interval=\"ONE_DAY\"\n",
        "        )\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            print(f\"No data for backtest: {ticker}\")\n",
        "            return None\n",
        "\n",
        "        df = df.copy()\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.sort_index()\n",
        "\n",
        "        atr_series = self._compute_atr_series(df)\n",
        "\n",
        "        dataset_builder = ImprovedExitDataset(df, verbose=False)\n",
        "        dataset_builder.process_data()\n",
        "        exit_df = dataset_builder.create_realistic_exit_dataset(\n",
        "            position_type=position_type,\n",
        "            max_holding_days=self.max_holding_days\n",
        "        )\n",
        "\n",
        "        if exit_df.empty:\n",
        "            print(f\"No trades generated for backtest: {ticker}\")\n",
        "            return None\n",
        "\n",
        "        atr_at_entry = []\n",
        "        entry_prices = []\n",
        "        for _, trade in exit_df.iterrows():\n",
        "            entry_date = trade['entry_date']\n",
        "            entry_date = pd.to_datetime(entry_date)\n",
        "            if entry_date in df.index:\n",
        "                atr_at_entry.append(float(atr_series.loc[entry_date]))\n",
        "                entry_prices.append(float(df.loc[entry_date, 'close']))\n",
        "            else:\n",
        "                atr_at_entry.append(np.nan)\n",
        "                entry_prices.append(np.nan)\n",
        "\n",
        "        exit_df['atr_entry'] = atr_at_entry\n",
        "        exit_df['entry_price'] = entry_prices\n",
        "\n",
        "        exit_df = exit_df.dropna(subset=['atr_entry', 'entry_price'])\n",
        "        if exit_df.empty:\n",
        "            print(f\"No trades with valid ATR/entry price for backtest: {ticker}\")\n",
        "            return None\n",
        "\n",
        "        baseline_returns = []\n",
        "        sl_returns = []\n",
        "\n",
        "        for _, trade in exit_df.iterrows():\n",
        "            entry_date = pd.to_datetime(trade['entry_date'])\n",
        "            exit_date = pd.to_datetime(trade['exit_date'])\n",
        "            entry_price = trade['entry_price']\n",
        "\n",
        "            if exit_date not in df.index or entry_date not in df.index:\n",
        "                continue\n",
        "\n",
        "            natural_exit_price = float(df.loc[exit_date, 'close'])\n",
        "\n",
        "            if position_type == 'long':\n",
        "                r_base = (natural_exit_price - entry_price) / entry_price\n",
        "            else:\n",
        "                r_base = (entry_price - natural_exit_price) / entry_price\n",
        "\n",
        "            baseline_returns.append(r_base)\n",
        "\n",
        "            sl_distance = self.atr_mult * float(trade['atr_entry'])\n",
        "\n",
        "            if position_type == 'long':\n",
        "                sl_price = entry_price - sl_distance\n",
        "            else:\n",
        "                sl_price = entry_price + sl_distance\n",
        "\n",
        "            trade_window = df.loc[entry_date:exit_date].iloc[1:]\n",
        "            hit_sl = False\n",
        "            sl_exit_price = None\n",
        "\n",
        "            for date_i, row_i in trade_window.iterrows():\n",
        "                low_i = row_i['low']\n",
        "                high_i = row_i['high']\n",
        "\n",
        "                if position_type == 'long':\n",
        "                    if low_i <= sl_price:\n",
        "                        hit_sl = True\n",
        "                        sl_exit_price = sl_price\n",
        "                        break\n",
        "                else:\n",
        "                    if high_i >= sl_price:\n",
        "                        hit_sl = True\n",
        "                        sl_exit_price = sl_price\n",
        "                        break\n",
        "\n",
        "            if hit_sl:\n",
        "                if position_type == 'long':\n",
        "                    r_sl = (sl_exit_price - entry_price) / entry_price\n",
        "                else:\n",
        "                    r_sl = (entry_price - sl_exit_price) / entry_price\n",
        "            else:\n",
        "                r_sl = r_base\n",
        "\n",
        "            sl_returns.append(r_sl)\n",
        "\n",
        "        if not baseline_returns:\n",
        "            print(f\"No testable trades for {ticker}\")\n",
        "            return None\n",
        "\n",
        "        baseline_returns = np.array(baseline_returns)\n",
        "        sl_returns = np.array(sl_returns)\n",
        "\n",
        "        def compute_stats(returns: np.ndarray):\n",
        "            equity = (1 + returns).cumprod()\n",
        "            peak = np.maximum.accumulate(equity)\n",
        "            dd = (equity - peak) / peak\n",
        "            max_dd = dd.min() if len(dd) > 0 else 0.0\n",
        "\n",
        "            return {\n",
        "                'num_trades': int(len(returns)),\n",
        "                'avg_return': float(returns.mean()),\n",
        "                'win_rate': float((returns > 0).mean()),\n",
        "                'max_drawdown': float(max_dd)\n",
        "            }\n",
        "\n",
        "        baseline_stats = compute_stats(baseline_returns)\n",
        "        sl_stats = compute_stats(sl_returns)\n",
        "\n",
        "        results = {\n",
        "            'ticker': ticker,\n",
        "            'position_type': position_type,\n",
        "            'baseline': baseline_stats,\n",
        "            'with_sl': sl_stats\n",
        "        }\n",
        "\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9qaljiM6UR4V"
      },
      "outputs": [],
      "source": [
        "def display_compact(ticker, long_exit, short_exit, prediction_date):\n",
        "    print(\n",
        "        f\"{ticker:11s} | {prediction_date:%Y-%m-%d} | \"\n",
        "        f\"L:{long_exit['recommendation']:<8s} \"\n",
        "        f\"(H{long_exit['holding_days']:>2}, R{long_exit['predicted_returns']*100:>6.2f}%, \"\n",
        "        f\"P{long_exit['success_probability']*100:>5.1f}%) | \"\n",
        "        f\"S:{short_exit['recommendation']:<8s} \"\n",
        "        f\"(H{short_exit['holding_days']:>2}, R{short_exit['predicted_returns']*100:>6.2f}%, \"\n",
        "        f\"P{short_exit['success_probability']*100:>5.1f}%)\"\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ticker_list = [\n",
        "        'ABB', 'ADANIENT', 'ADANIPORTS', 'ADANIPOWER', 'AMBUJACEM', 'APOLLOHOSP',\n",
        "        'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV',\n",
        "        'BAJAJHLDNG', 'BAJAJHFL', 'BANKBARODA', 'BEL', 'BPCL', 'BHARTIARTL',\n",
        "        'BOSCHLTD', 'BRITANNIA', 'CGPOWER', 'CANBK', 'CHOLAFIN', 'CIPLA',\n",
        "        'COALINDIA', 'DLF', 'DABUR', 'DIVISLAB', 'DRREDDY', 'EICHERMOT',\n",
        "        'ETERNAL', 'GAIL', 'GODREJCP', 'GRASIM', 'HCLTECH', 'HDFCBANK',\n",
        "        'HDFCLIFE', 'HAVELLS', 'HEROMOTOCO', 'HINDALCO', 'HAL', 'HINDUNILVR',\n",
        "        'HYUNDAI', 'ICICIBANK', 'ICICIGI', 'ICICIPRULI', 'ITC', 'INDHOTEL',\n",
        "        'IOC', 'IRFC', 'INDUSINDBK', 'NAUKRI', 'INFY', 'INDIGO', 'JSWENERGY',\n",
        "        'JSWSTEEL', 'JINDALSTEL', 'KOTAKBANK', 'LTIM', 'LT', 'LICI', 'M&M',\n",
        "        'MARUTI', 'NTPC', 'NESTLEIND', 'ONGC', 'PIDILITIND', 'PFC', 'POWERGRID',\n",
        "        'PNB', 'RECLTD', 'RELIANCE', 'SBILIFE', 'MOTHERSON', 'SHREECEM',\n",
        "        'SHRIRAMFIN', 'SIEMENS', 'SBIN', 'SUNPHARMA', 'TVSMOTOR', 'TCS',\n",
        "        'TATACONSUM', 'TATAMOTORS', 'TATAPOWER', 'TATASTEEL', 'TECHM', 'TITAN',\n",
        "        'TORNTPHARM', 'TRENT', 'ULTRACEMCO', 'UNITDSPR', 'VBL', 'VEDL', 'WIPRO',\n",
        "        'ZYDUSLIFE'\n",
        "    ]\n",
        "\n",
        "    api_key = \"\"\n",
        "    user_id = \"\"\n",
        "    password = \"\"\n",
        "    totp_secret = \"\"\n",
        "\n",
        "    prediction_date = datetime(2025, 7, 15)\n",
        "    n_trials = 20\n",
        "    lookback_years = 5\n",
        "    horizon_days = 5\n",
        "\n",
        "    Exit = None\n",
        "    max_retries = 3\n",
        "    backoff_seconds = 5\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            Exit = ExitStrategySystem(api_key, user_id, password, totp_secret, verbose=False)\n",
        "            Exit.login()\n",
        "            Exit.fetch_instruments()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            logging.error(f\"login failed attempt {attempt+1}: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(backoff_seconds)\n",
        "            else:\n",
        "                raise SystemExit(1)\n",
        "\n",
        "    print(f\"STARTING BATCH PREDICTION FOR {len(ticker_list)} STOCKS | Prediction Date: {prediction_date:%Y-%m-%d}\\n\")\n",
        "\n",
        "    all_predictions = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, ticker in enumerate(ticker_list, 1):\n",
        "        try:\n",
        "            long_exit, short_exit = Exit.predict_exit_signals(\n",
        "                ticker=ticker,\n",
        "                current_date=prediction_date,\n",
        "                horizon_days=horizon_days,\n",
        "                n_trials=n_trials,\n",
        "                lookback_years=lookback_years\n",
        "            )\n",
        "            if long_exit is None or short_exit is None:\n",
        "                continue\n",
        "            display_compact(ticker, long_exit, short_exit, prediction_date)\n",
        "            all_predictions.append({\n",
        "                'ticker': ticker,\n",
        "                'prediction_date': prediction_date.strftime('%Y-%m-%d'),\n",
        "                'long_holding_days': long_exit['holding_days'],\n",
        "                'long_returns': long_exit['predicted_returns'],\n",
        "                'long_success_prob': long_exit['success_probability'],\n",
        "                'long_risk_score': long_exit['risk_score'],\n",
        "                'long_confidence': long_exit['confidence'],\n",
        "                'long_recommendation': long_exit['recommendation'],\n",
        "                'short_holding_days': short_exit['holding_days'],\n",
        "                'short_returns': short_exit['predicted_returns'],\n",
        "                'short_success_prob': short_exit['success_probability'],\n",
        "                'short_risk_score': short_exit['risk_score'],\n",
        "                'short_confidence': short_exit['confidence'],\n",
        "                'short_recommendation': short_exit['recommendation'],\n",
        "            })\n",
        "        except Exception as e:\n",
        "            logging.error(f\"prediction failed for {ticker}: {e}\")\n",
        "            continue\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    if not all_predictions:\n",
        "        print(\"\\nNo predictions were successful. Check logs.\")\n",
        "        raise SystemExit(1)\n",
        "\n",
        "    predictions_df = pd.DataFrame(all_predictions)\n",
        "\n",
        "    print(\"\\n=== SUMMARY ===\")\n",
        "    cols = ['ticker','long_recommendation','short_recommendation',\n",
        "            'long_holding_days','long_returns','long_success_prob',\n",
        "            'short_holding_days','short_returns','short_success_prob']\n",
        "    print(predictions_df[cols].to_string(index=False))\n",
        "\n",
        "    output_file = f'exit_predictions_{prediction_date:%Y%m%d}.csv'\n",
        "    predictions_df.to_csv(output_file, index=False)\n",
        "    print(f\"\\nSaved: {output_file}\")\n",
        "\n",
        "    # STOP LOSS CALCULATION FOR STRONG / MODERATE SIGNALS\n",
        "    sl_calc = StopLossCalculator(\n",
        "        exit_system=Exit,\n",
        "        atr_period=14,\n",
        "        lookback_days=60,\n",
        "        atr_mult_strong=1.8,\n",
        "        atr_mult_moderate=1.2,\n",
        "        min_sl_pct=0.01,\n",
        "        max_sl_pct=0.06,\n",
        "        tick_size=0.05\n",
        "    )\n",
        "\n",
        "    predictions_with_sl = sl_calc.add_stop_losses(predictions_df, prediction_date)\n",
        "\n",
        "    mask = (~predictions_with_sl['long_sl_price'].isna()) | (~predictions_with_sl['short_sl_price'].isna())\n",
        "    sl_view = predictions_with_sl[mask][[\n",
        "        'ticker',\n",
        "        'long_recommendation', 'long_holding_days', 'long_returns', 'long_success_prob',\n",
        "        'long_sl_pct', 'long_sl_price',\n",
        "        'short_recommendation', 'short_holding_days', 'short_returns', 'short_success_prob',\n",
        "        'short_sl_pct', 'short_sl_price'\n",
        "    ]]\n",
        "\n",
        "    print(\"\\n=== STOP LOSS RECOMMENDATIONS (ONLY STRONG / MODERATE) ===\")\n",
        "    if not sl_view.empty:\n",
        "        print(sl_view.to_string(index=False))\n",
        "    else:\n",
        "        print(\"No STRONG/MODERATE signals with valid SL computed.\")\n",
        "\n",
        "    output_file_sl = f'exit_predictions_with_sl_{prediction_date:%Y%m%d}.csv'\n",
        "    predictions_with_sl.to_csv(output_file_sl, index=False)\n",
        "    print(f\"\\nSaved with stop-loss levels: {output_file_sl}\")\n",
        "\n",
        "\n",
        "    # SIMPLE BACKTEST\n",
        "    RUN_BACKTEST = True\n",
        "\n",
        "    if RUN_BACKTEST:\n",
        "        backtester = SimpleSLBacktester(\n",
        "            exit_system=Exit,\n",
        "            max_holding_days=20,\n",
        "            atr_period=14,\n",
        "            atr_mult=1.5\n",
        "        )\n",
        "\n",
        "        bt_result = backtester.backtest_single_ticker(\n",
        "            ticker='ABB',\n",
        "            start_date=datetime(2020, 7, 15),\n",
        "            end_date=prediction_date,\n",
        "            position_type='long'\n",
        "        )\n",
        "\n",
        "        if bt_result is not None:\n",
        "            print(\"\\n=== SIMPLE SL BACKTEST RESULT (ABB, LONG) ===\")\n",
        "            print(\"Baseline:\", bt_result['baseline'])\n",
        "            print(\"With SL :\", bt_result['with_sl'])\n",
        "        else:\n",
        "            print(\"\\nBacktest did not produce results for ABB.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
